{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Internet Repositories used in our research\n",
        "\n",
        "'This repository was used from us to have a better understanding on how to incorporate Markovify and use the rhyme system'\n",
        "'https://www.kaggle.com/code/alcoach/arabic-poem-generator/notebook'\n",
        "\n",
        "'This repository was used from us to figure out the struxture and how to build and combine an LSTM model and Marovify'\n",
        "'https://github.com/helloMinji/AI-RAPSTAR/blob/master/model.py'\n",
        "\n",
        "'This repository was used from us to gain a better understanding on how to configure the LSTM model'\n",
        "'https://colab.research.google.com/drive/1wlZXZBvOo93pAmTtEUeTlPsgAP4D1bLA#scrollTo=I5EngGk8YuJv'\n",
        "\n",
        "'This code found on StackOverflow helped us understand and code the count of syllables'\n",
        "'https://stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mkiWbgOCyeSi",
        "outputId": "d2008f9e-e37d-4a28-9fe7-9de26b8cdb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJqTBepLhs_b",
        "outputId": "4ff70669-aa74-4a4b-eca8-149a54eab31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 13.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18628 sha256=ad91a9a80fd6eb29af564f75264b2b229d04dd47810c00e4c47064f31f8923b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/c5/82/11125c5a7dadec27ef49ac2b3a12d3b1f79ff7333c92a9b67b\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.9.4 unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pronouncing\n",
            "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
            "Collecting cmudict>=0.4.0\n",
            "  Downloading cmudict-1.0.2-py2.py3-none-any.whl (939 kB)\n",
            "\u001b[K     |████████████████████████████████| 939 kB 8.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6252 sha256=162e38e3f4ea51790a163eb7c595404526904944e9ac5734db63f537df55431e\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e8/c0/3606d42fdbf5f3871564eb6a353591a8f5deeed013fdb73921\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-1.0.2 pronouncing-0.2.0\n"
          ]
        }
      ],
      "source": [
        "# Taking care of dependencies needed throughout the code\n",
        "!pip install markovify\n",
        "!pip install pronouncing\n",
        "# Imports\n",
        "import markovify\n",
        "import re\n",
        "import pronouncing\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "haowk4QumdIy"
      },
      "outputs": [],
      "source": [
        "# Load dataset in .txt format and UTF8 encoding /content/sample_data/Bars.txt\n",
        "with open('Bars.txt', encoding=\"utf8\") as f:\n",
        "    noted_rap = f.read()\n",
        "# Split the dataset into lines\n",
        "ed_rap = [x.split(\"\\r\")[0] for x in noted_rap.split(\"\\n\")]\n",
        "# Remove spaces\n",
        "while \"\" in ed_rap:\n",
        "  ed_rap.remove(\"\")\n",
        "while \" \" in ed_rap:\n",
        "  ed_rap.remove(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOdpjOL1I01n",
        "outputId": "e9192358-b9a4-4d9c-825b-45336b1e4ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufefftext', 'Heartbreak drowned sorrows in a large steak', 'Why you always all on my back?', 'Why you gotta do me like that?', \"Why you gotta act like a bitch when I'm with you?\", \"Baby girl I'm blue\", 'Because you treat me like shit', 'I paid for the bed and never even slept in it', 'I paid for that crib I never stepped foot in', 'And now somebody else is eating all the pudding']\n"
          ]
        }
      ],
      "source": [
        "# Test: print first 10 rap lines to be sure dataset is correctly loaded\n",
        "print(f'{ed_rap[:10]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jHqn_xgJbkk"
      },
      "outputs": [],
      "source": [
        "def make_model(depth):\n",
        "    '''Function that takes as input the depth of the network.\n",
        "     Returns the model'''\n",
        "    model = Sequential()\n",
        "    # Add a LSTM layer with 4 units with input_shape of (2,2)\n",
        "    model.add(LSTM(4, input_shape=(2, 2), return_sequences=True))\n",
        "    # Add as many number of layers as depth. Each layer has 8 nodes\n",
        "    for i in range(depth):\n",
        "        model.add(LSTM(8, return_sequences=True))\n",
        "    # Adds a LSTM layer with 2 nodes (output)\n",
        "    model.add(LSTM(2, return_sequences=True))\n",
        "    # Set up RMSprop as the optimizer and MSE as the loss function\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='mse')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnpynqMUNhC-"
      },
      "outputs": [],
      "source": [
        "def syllables(line):\n",
        "    '''Check that length of a bar is not longer than maxsyllables.\n",
        "       Generate bars until the number of syllables is less than maxsyllables.'''\n",
        "    cntr = 0\n",
        "    for word in line.split(\" \"):\n",
        "        vowels = 'aeiouy'\n",
        "        word = word.lower().strip(\".:;?!\")\n",
        "        if not word:\n",
        "            continue\n",
        "        if word[0] in vowels:\n",
        "            cntr += 1\n",
        "        for index in range(1, len(word)):\n",
        "            if word[index] in vowels and word[index - 1] not in vowels:\n",
        "                cntr += 1\n",
        "        if word.endswith('e'):\n",
        "            cntr -= 1\n",
        "        if word.endswith('le'):\n",
        "            cntr += 1\n",
        "        if cntr == 0:\n",
        "            cntr += 1\n",
        "    return cntr / maxsyllables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ7GXujmO5dQ"
      },
      "outputs": [],
      "source": [
        "def rhymeindex(lyrics):\n",
        "    '''Build a rhyme list. Write the list on a file.'''\n",
        "    # Check if the list is already made\n",
        "    if str('list') + \".rhymes\" in os.listdir(\".\"):\n",
        "        print('Loading rhymes from ' + str('list') + \".rhymes\")\n",
        "        return open(str('list') + \".rhymes\", \"r\",encoding='utf-8').read().split(\"\\n\")\n",
        "    # If not, build list of rhymes\n",
        "    else:\n",
        "        nrlist = []\n",
        "        for i in lyrics:\n",
        "            word = re.sub(r\"\\W+\", '', i.split(\" \")[-1]).lower()\n",
        "            rhymeslist = pronouncing.rhymes(word)\n",
        "            rhymeslistends = []      \n",
        "            for i in rhymeslist:\n",
        "                rhymeslistends.append(i[-2:])\n",
        "            try:\n",
        "                rhymescheme = max(set(rhymeslistends), key=rhymeslistends.cntr)\n",
        "            except Exception:\n",
        "                rhymescheme = word[-2:]\n",
        "            nrlist.append(rhymescheme)\n",
        "        # Use set() to make the list unique\n",
        "        nrlist = list(set(nrlist))\n",
        "        reverselist = [x[::-1] for x in nrlist]\n",
        "        # Sort reverselist\n",
        "        reverselist = sorted(reverselist)\n",
        "        rhymelist = [x[::-1] for x in reverselist]\n",
        "        f = open(str('list') + \".rhymes\", \"w\", encoding='utf-8')\n",
        "        f.write(\"\\n\".join(rhymelist))\n",
        "        f.close()\n",
        "        return rhymelist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNc_7qhkPQyM"
      },
      "outputs": [],
      "source": [
        "def rhyme(line, rhyme_list):\n",
        "    '''Find most common rhyme ending using max() function.\n",
        "       If found, convert to float'''\n",
        "    word = re.sub(r\"\\W+\", '', line.split(\" \")[-1]).lower()\n",
        "    rhymeslist = pronouncing.rhymes(word)\n",
        "    rhymeslist = [x.encode('UTF8') for x in rhymeslist]\n",
        "    rhymeslistends = []\n",
        "    for i in rhymeslist:\n",
        "        rhymeslistends.append(i[-2:])\n",
        "    try:\n",
        "        # Use set() to choose unique rhymes\n",
        "        rhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
        "    except Exception:\n",
        "        rhymescheme = word[-2:]\n",
        "    try:\n",
        "        float_rhyme = rhyme_list.index(rhymescheme)\n",
        "        float_rhyme = float_rhyme / float(len(rhyme_list))\n",
        "        return float_rhyme\n",
        "    except Exception:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD-yoUZXVb6H"
      },
      "outputs": [],
      "source": [
        "def get_last_word(bar):\n",
        "    '''Get the last word of the bar'''\n",
        "    for last_word in bar.split(\" \"):\n",
        "        last_word = bar.split(\" \")[-1]\n",
        "        if len(last_word) == 0:\n",
        "          last_word = bar.split(\" \")[-2]\n",
        "        # Check if the last word is punctuation.\n",
        "        # If this is the case, get the word before it\n",
        "        if not last_word[-1] in \"/!.?,\":\n",
        "            continue\n",
        "        if last_word[-1] in \"/!.?,\":\n",
        "            last_word = last_word[:-1]\n",
        "    return last_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ2llLxxRSXX"
      },
      "outputs": [],
      "source": [
        "def generate_lyrics(lyrics_file):\n",
        "    '''Using Markov model (markovify), generate lyrics'''\n",
        "    bars = []\n",
        "    last_words = []\n",
        "    linelength = len(lyrics_file)\n",
        "    cntr = 0\n",
        "    markov_model = markovify.NewlineText(ed_rap)\n",
        "    #markov_model = markov((\". \").join(lyrics_file) + \".\")\n",
        "\n",
        "    # While the length of the bars is less than linelength/9\n",
        "    # and the counter is less than double the linelength, return a bar\n",
        "    # (We use the while loop to to prevent overlapping of the newly generated text\n",
        "    # and the original one).\n",
        "    while len(bars) < linelength / 9 and cntr < linelength * 2:\n",
        "        bar = markov_model.make_sentence()\n",
        "\n",
        "        # Check that syllables is under the max number of syllables\n",
        "        if type(bar) != type(None) and syllables(bar) < 1 and len(bar.split(\" \")[-1]) != 0:\n",
        "            last_word = get_last_word(bar)\n",
        "            # Check if the bar is unique and that last_word is not overused\n",
        "            # (In this setting, we set maximum number of times as 3)\n",
        "            if bar not in bars and last_words.count(last_word) < 3:\n",
        "                bars.append(bar)\n",
        "                last_words.append(last_word)\n",
        "                cntr += 1\n",
        "\n",
        "    return bars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpRmkrrRWD0r"
      },
      "outputs": [],
      "source": [
        "def build_dataset(lyrics, rhyme_list):\n",
        "    '''Generate inputs in the correct shape (2x2 tensors)'''\n",
        "    '''lyrics can be the original text or the already trained data'''\n",
        "    dataset = []\n",
        "    line_list = []\n",
        "    # For each line in lyrics, make a list composed by:\n",
        "    # - the line itself\n",
        "    # - the output of syllables() for that line\n",
        "    # - the output of rhyme (most common word endingssyllables of the line (values range from) the line, the syllables\n",
        "    # line_list becomes a list of the line from the lyrics, the syllables for that line (either 0 or 1 since\n",
        "    # syllables uses integer division by maxsyllables (16)), and then rhyme returns the most common\n",
        "    # word endings of possible rhyming words\n",
        "    for line in lyrics:\n",
        "        line_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
        "        dataset.append(line_list)\n",
        "\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "\n",
        "    for i in range(len(dataset) - 3):\n",
        "        line1 = dataset[i][1:]\n",
        "        line2 = dataset[i + 1][1:]\n",
        "        line3 = dataset[i + 2][1:]\n",
        "        line4 = dataset[i + 3][1:]\n",
        "\n",
        "        # Add datapoints. Start from a list of two pairs of (syllable, rhyme_index)\n",
        "        x = [line1[0], line1[1], line2[0], line2[1]]\n",
        "        x = np.array(x)\n",
        "        # Reshape as a 2x2 tensor to adhere with LSTM model requirements\n",
        "        # Each row is now a [syllable, rhyme_index] pair\n",
        "        x = x.reshape(2, 2)\n",
        "        \n",
        "\n",
        "        # Do the same for the target data\n",
        "        y = [line3[0], line3[1], line4[0], line4[1]]\n",
        "        y = np.array(y)\n",
        "        y = y.reshape(2, 2)\n",
        "\n",
        "        # Sanity check for the types\n",
        "        if type(x) is np.ndarray and type(y) is np.ndarray:\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    # Convert to array\n",
        "    x_data = np.array(x_data)\n",
        "    y_data = np.array(y_data)\n",
        "    \n",
        "    return x_data, y_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-o3Pkb5Z7yy"
      },
      "outputs": [],
      "source": [
        "def compose_rap(lines, rhyme_list, lyrics_file, model):\n",
        "    rap_vectors = []\n",
        "\n",
        "    # Check if any empty lines are present and remove them\n",
        "    while \"\" in lyrics_file:\n",
        "        lyrics_file.remove(\"\")\n",
        "\n",
        "    # Start generation process from a random line from lyrics_file.\n",
        "    # Create a list of 2 lines\n",
        "    initial_index = random.choice(range(len(lyrics_file) - 1))\n",
        "    initial_lines = lyrics_file[initial_index:initial_index + 8]\n",
        "\n",
        "    starting_input = []\n",
        "    # For each line in initial_lines,\n",
        "    # append a (syllable,rhyme_index) pair to starting_input\n",
        "    for line in initial_lines:\n",
        "        starting_input.append([syllables(line), rhyme(line, rhyme_list)])\n",
        "\n",
        "    # Generate output predictions for starting_input\n",
        "    # Perform sanity check of the type of starting_input to be sure it's float32\n",
        "    starting_vectors = model.predict(np.array([starting_input]).flatten().reshape(4, 2, 2).astype('float32'))\n",
        "    rap_vectors.append(starting_vectors)\n",
        "\n",
        "    # Repeat the process for the desired length of the rap \n",
        "    for i in range(rap_length):\n",
        "        rap_vectors.append(model.predict(np.array([rap_vectors[-1]]).flatten().reshape(4, 2, 2)))\n",
        "\n",
        "    return rap_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC_SQjA1anpk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "ef02d66a-4744-4232-f399-e6f36b33b34a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def vectors_into_song(vectors, generated_lyrics, rhyme_list):\\n\\tdef last_word_compare(rap, line2):\\n\\t\\tpenalty = 0 \\n\\t\\tfor line1 in rap:\\n\\t\\t\\tword1 = line1.split(\" \")[-1]\\n\\t\\t\\tword2 = line2.split(\" \")[-1]\\n\\t\\t\\tif word1[-1] in \"?!,.\":\\n\\t\\t\\t\\tword1 = word1[:-1]\\n\\t\\t\\tif word2[-1] in \"?!,.\":\\n\\t\\t\\t\\tword2 = word2[:-1]\\n\\t\\t\\tif word1 == word2:\\n\\t\\t\\t\\tpenalty += 0.2\\n\\t\\treturn penalty\\n\\tdef calculate_score(vector_half, syllables, rhyme, penalty):\\n\\t\\tdesired_syllables = vector_half[0]\\n\\t\\tdesired_rhyme = vector_half[1]\\n\\t\\tdesired_syllables = desired_syllables * maxsyllables\\n\\t\\tdesired_rhyme = desired_rhyme * len(rhyme_list)\\n\\t\\tscore = 1.0 - abs(float(desired_syllables) - float(syllables)) + abs(float(desired_rhyme) - float(rhyme)) - penalty\\n\\t\\treturn score\\n\\tdataset = []\\n\\tfor line in generated_lyrics:\\n\\t\\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\\n\\t\\tdataset.append(line_list)\\n\\trap = []\\n\\tvector_halves = []\\n\\tfor vector in vectors:\\n\\t\\tvector_halves.append(list(vector[0][0])) \\n\\t\\tvector_halves.append(list(vector[0][1]))\\n\\tfor vector in vector_halves:\\n\\t\\tscorelist = []\\n\\t\\tfor item in dataset:\\n\\t\\t\\tline = item[0]\\n\\t\\t\\tif len(rap) != 0:\\n\\t\\t\\t\\tpenalty = last_word_compare(rap, line)\\n\\t\\t\\telse:\\n\\t\\t\\t\\tpenalty = 0\\n\\t\\t\\ttotal_score = calculate_score(vector, item[1], item[2], penalty)\\n\\t\\t\\tscore_entry = [line, total_score]\\n\\t\\t\\tscorelist.append(score_entry)\\n\\t\\tfixed_score_list = []\\n\\t\\tfor score in scorelist:\\n\\t\\t\\tfixed_score_list.append(float(score[1]))\\n\\t\\tmax_score = max(fixed_score_list)\\n\\t\\tfor item in scorelist:\\n\\t\\t\\tif item[1] == max_score:\\n\\t\\t\\t\\trap.append(item[0])\\n\\t\\t\\t\\tfor i in dataset:\\n\\t\\t\\t\\t\\tif item[0] == i[0]:\\n\\t\\t\\t\\t\\t\\tdataset.remove(i)\\n\\t\\t\\t\\t\\t\\tbreak\\n\\t\\t\\t\\tbreak     \\n\\treturn rap'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "'''def vectors_into_song(vectors, generated_lyrics, rhyme_list):\n",
        "\tdef last_word_compare(rap, line2):\n",
        "\t\tpenalty = 0 \n",
        "\t\tfor line1 in rap:\n",
        "\t\t\tword1 = line1.split(\" \")[-1]\n",
        "\t\t\tword2 = line2.split(\" \")[-1]\n",
        "\t\t\tif word1[-1] in \"?!,.\":\n",
        "\t\t\t\tword1 = word1[:-1]\n",
        "\t\t\tif word2[-1] in \"?!,.\":\n",
        "\t\t\t\tword2 = word2[:-1]\n",
        "\t\t\tif word1 == word2:\n",
        "\t\t\t\tpenalty += 0.2\n",
        "\t\treturn penalty\n",
        "\tdef calculate_score(vector_half, syllables, rhyme, penalty):\n",
        "\t\tdesired_syllables = vector_half[0]\n",
        "\t\tdesired_rhyme = vector_half[1]\n",
        "\t\tdesired_syllables = desired_syllables * maxsyllables\n",
        "\t\tdesired_rhyme = desired_rhyme * len(rhyme_list)\n",
        "\t\tscore = 1.0 - abs(float(desired_syllables) - float(syllables)) + abs(float(desired_rhyme) - float(rhyme)) - penalty\n",
        "\t\treturn score\n",
        "\tdataset = []\n",
        "\tfor line in generated_lyrics:\n",
        "\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
        "\t\tdataset.append(line_list)\n",
        "\trap = []\n",
        "\tvector_halves = []\n",
        "\tfor vector in vectors:\n",
        "\t\tvector_halves.append(list(vector[0][0])) \n",
        "\t\tvector_halves.append(list(vector[0][1]))\n",
        "\tfor vector in vector_halves:\n",
        "\t\tscorelist = []\n",
        "\t\tfor item in dataset:\n",
        "\t\t\tline = item[0]\n",
        "\t\t\tif len(rap) != 0:\n",
        "\t\t\t\tpenalty = last_word_compare(rap, line)\n",
        "\t\t\telse:\n",
        "\t\t\t\tpenalty = 0\n",
        "\t\t\ttotal_score = calculate_score(vector, item[1], item[2], penalty)\n",
        "\t\t\tscore_entry = [line, total_score]\n",
        "\t\t\tscorelist.append(score_entry)\n",
        "\t\tfixed_score_list = []\n",
        "\t\tfor score in scorelist:\n",
        "\t\t\tfixed_score_list.append(float(score[1]))\n",
        "\t\tmax_score = max(fixed_score_list)\n",
        "\t\tfor item in scorelist:\n",
        "\t\t\tif item[1] == max_score:\n",
        "\t\t\t\trap.append(item[0])\n",
        "\t\t\t\tfor i in dataset:\n",
        "\t\t\t\t\tif item[0] == i[0]:\n",
        "\t\t\t\t\t\tdataset.remove(i)\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\tbreak     \n",
        "\treturn rap'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFxZtGpArsQ2"
      },
      "outputs": [],
      "source": [
        "def vectors_into_song(vectors, generated_lyrics, rhyme_list):\n",
        "    ###Convert vectors into lyrics.\n",
        "    ###   vectors: 2x2 predicted bars generated by compose_rap()\n",
        "    \n",
        "    # Comparing the last words between the original and the generated lyrics\n",
        "    # granting a penalty if they are the same.\n",
        "    def last_word_compare(rap, line2):\n",
        "        penalty = 0\n",
        "        for line1 in rap:\n",
        "            word1 = line1.split(\" \")[-1]\n",
        "            word2 = line2.split(\" \")[-1]\n",
        "\n",
        "            # remove punctuations\n",
        "            if word1[-1] in \"?!,.\":\n",
        "                word1 = word1[:-1]\n",
        "\n",
        "            if word2[-1] in \"?!,.\":\n",
        "                word2 = word2[:-1]\n",
        "\n",
        "            if word1 == word2:\n",
        "                penalty += 0.2\n",
        "\n",
        "        return penalty\n",
        "\n",
        "    # vector_half is a single [syllable, rhyme_index] pair\n",
        "    # returns a score rating for a given line\n",
        "    def calculate_score(vector_half, syllables, rhyme, penalty):\n",
        "        desired_syllables = vector_half[0]\n",
        "        desired_rhyme = vector_half[1]\n",
        "        # number of syllables\n",
        "        desired_syllables = desired_syllables * maxsyllables\n",
        "        # index of rhymes\n",
        "        desired_rhyme = desired_rhyme * len(rhyme_list)\n",
        "\n",
        "        # score from 1 substracts the sum of the difference between\n",
        "        # predicted syllables and generated syllables and the difference between\n",
        "        # the predicted rhyme and generated rhyme and then subtracts the penalty\n",
        "        score = 1.0 - (abs((float(desired_syllables) - float(syllables))) + abs(\n",
        "            (float(desired_rhyme) - float(rhyme)))) - penalty\n",
        "\n",
        "        return score\n",
        "\n",
        "    # First generate a list of all the lines. Each of them is combined with its syllables\n",
        "    # and its rhyme float value\n",
        "    dataset = []\n",
        "    for line in generated_lyrics:\n",
        "        line_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
        "        dataset.append(line_list)\n",
        "\n",
        "    rap = []\n",
        "\n",
        "    vector_halves = []\n",
        "    # Then separate each vector into half (or one bar)\n",
        "    # Each bar is composed by a (syllables, rhyme_index) pair\n",
        "    for vector in vectors:\n",
        "        vector_halves.append(list(vector[0][0]))\n",
        "        vector_halves.append(list(vector[0][1]))\n",
        "\n",
        "    # Score each vector against every generated line/bar (item) to find the most\n",
        "    # suitable bar predicted (by looking at the highest score).\n",
        "    # Add bar to final lyrics and remove from the dataset to avoid duplicates\n",
        "    for vector in vector_halves:\n",
        "        scorelist = []\n",
        "        # For each genereated bar from Markov model in the dataset\n",
        "        for item in dataset:\n",
        "\n",
        "            line = item[0]\n",
        "\n",
        "            #Start with penaly 0, then compare the last word to assign penalty\n",
        "            if len(rap) != 0:\n",
        "                penalty = last_word_compare(rap, line)\n",
        "            else:\n",
        "                penalty = 0\n",
        "\n",
        "            # calculate line score\n",
        "            total_score = calculate_score(vector, item[1], item[2], penalty)\n",
        "            # Bind the total score of the line with itself and put it as an entry\n",
        "            score_entry = [line, total_score]\n",
        "            # Add the entry to a score list\n",
        "            scorelist.append(score_entry)\n",
        "\n",
        "        fixed_score_list = []\n",
        "        # Take only the score from each entry and append to fixed_score_list\n",
        "        for score in scorelist:\n",
        "            fixed_score_list.append((score[1]))\n",
        "        # Continue if fixed_score_list is empty \n",
        "        if not fixed_score_list:\n",
        "            continue\n",
        "        # # Retrieve line associated with the max score from fixed_score_list\n",
        "        max_score = max(fixed_score_list)\n",
        "        print(f'score: {max_score}')\n",
        "        for item in scorelist:\n",
        "            if item[1] == max_score:\n",
        "                # Add bar to final lyrics\n",
        "                rap.append(item[0])\n",
        "                # Remove the line from the dataset to avoid duplication\n",
        "                for i in dataset:\n",
        "                    if item[0] == i[0]:\n",
        "                        dataset.remove(i)\n",
        "                        break\n",
        "                break\n",
        "    return rap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KZNKyM2MRZiP"
      },
      "outputs": [],
      "source": [
        "def main(depth):\n",
        "    '''End-to-end function. Create the model, the rhyme list, the dataset.\n",
        "       Train the model, generate bars, convert to vectors and then into lyrics.\n",
        "       Print the generated lyrics.'''\n",
        "    train_mode = True\n",
        "\n",
        "    # Create the model\n",
        "    model = make_model(depth)\n",
        "    \n",
        "    # Make a \"copy\" of the edited rap as a sanity check\n",
        "    text_file = ed_rap\n",
        "    \n",
        "    # Check if any empty lines are present and remove them\n",
        "    while \"\" in text_file:\n",
        "        text_file.remove(\"\")\n",
        "    \n",
        "    # Make a \"copy\" of text_file as a sanity check\n",
        "    bars = text_file\n",
        "\n",
        "    # Delete the first rhyme (empty rhyme '')\n",
        "    rhyme_list = rhymeindex(bars)\n",
        "    del rhyme_list[0]\n",
        "    # For loop to test which rhymes are biased (chosen by the model but not human-generated lyrics)\n",
        "    remove_list = ['y', 'ay', 'by', 'cy', 'dy', 'ey', 'fy', 'hy', 'ky', 'ly', 'my', 'ny', 'oy', 'py', 'ry', 'sy', 'uy', 'vy', 'wy', 'xy', 'yy', 'zy', 'z', 'az', 'dz', 'ez', 'gz', 'hz', 'iz', 'lz', 'mz', 'nz']\n",
        "    for rhyme in remove_list:\n",
        "      rhyme_list.remove(rhyme)\n",
        "    \n",
        "    # Print rhyme list\n",
        "    print(f'rhyme_list: {rhyme_list}')\n",
        "\n",
        "    # Build the dataset and convert to float32 array\n",
        "    x_data, y_data = build_dataset(bars, rhyme_list)\n",
        "    x_data = np.asarray(x_data).astype('float32')\n",
        "    y_data = np.asarray(y_data).astype('float32')\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(np.array(x_data), np.array(y_data),\n",
        "          batch_size=32,\n",
        "          epochs=epochs_to_train,\n",
        "          verbose=1)\n",
        "    \n",
        "    # Generate lyrics\n",
        "    bars = generate_lyrics(text_file)\n",
        "\n",
        "    # Compose rap\n",
        "    vectors = compose_rap(bars, rhyme_list, text_file, model)\n",
        "\n",
        "    # Turn vectors into song\n",
        "    rap = vectors_into_song(vectors, bars, rhyme_list)\n",
        "    \n",
        "    # Print generated lyrics\n",
        "    for bar in rap:\n",
        "        print(bar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXx1lJ9H-tPr",
        "scrolled": true,
        "outputId": "22478977-7621-4617-d9ca-6606fa8c6561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading rhymes from list.rhymes\n",
            "rhyme_list: ['0', '00', '10', '20', '30', '40', '50', '60', '80', '90', 'e0', '1', '01', '11', '21', '71', '91', 'a1', 'e1', 's1', '2', '02', '12', '22', '32', '42', '62', '72', '82', '92', 'k2', 'n2', 't2', 'u2', 'v2', 'w2', 'x2', '3', '03', '13', '23', '63', '73', '83', '93', 'c3', 'm3', 'o3', 'p3', 'x3', '4', '04', '14', '24', '34', '44', '54', '64', '74', '84', '94', 'b4', 'c4', 'x4', '5', '05', '15', '25', '35', '45', '55', '65', '75', '85', '95', 'c5', 'g5', 'x5', '6', '06', '16', '26', '36', '46', '56', '76', '86', '96', 'x6', '7', '07', '17', '47', '57', '67', '77', '87', '97', 'x7', '8', '08', '18', '28', '38', '48', '68', '88', '98', 'v8', 'x8', '9', '09', '19', '39', '59', '69', '79', '89', '99', 'b9', 'c9', 'h9', 'a', 'aa', 'ba', 'ca', 'da', 'ea', 'fa', 'ga', 'ha', 'ia', 'ja', 'ka', 'la', 'ma', 'na', 'oa', 'pa', 'ra', 'sa', 'ta', 'ua', 'va', 'wa', 'ya', 'za', 'ça', 'b', 'ab', 'cb', 'db', 'eb', 'ib', 'lb', 'mb', 'nb', 'ob', 'qb', 'rb', 'tb', 'ub', 'c', 'ac', 'bc', 'cc', 'dc', 'ec', 'fc', 'hc', 'ic', 'lc', 'mc', 'nc', 'oc', 'pc', 'rc', 'sc', 'tc', 'uc', 'yc', 'ōc', 'd', '3d', 'ad', 'bd', 'cd', 'dd', 'ed', 'gd', 'hd', 'id', 'kd', 'ld', 'md', 'nd', 'od', 'pd', 'rd', 'sd', 'td', 'ud', 'vd', 'wd', 'yd', 'e', '6e', 'ae', 'be', 'ce', 'de', 'ee', 'fe', 'ge', 'he', 'ie', 'je', 'ke', 'le', 'me', 'ne', 'oe', 'pe', 're', 'se', 'te', 'ue', 've', 'we', 'xe', 'ye', 'ze', 'ée', 'f', 'af', 'cf', 'ef', 'ff', 'if', 'lf', 'mf', 'nf', 'of', 'pf', 'rf', 'tf', 'wf', 'g', '4g', 'ag', 'bg', 'cg', 'eg', 'gg', 'ig', 'kg', 'mg', 'ng', 'og', 'pg', 'rg', 'ug', 'wg', 'yg', 'h', 'ah', 'ch', 'eh', 'gh', 'hh', 'ih', 'kh', 'mh', 'nh', 'oh', 'ph', 'sh', 'th', 'uh', 'i', 'ai', 'bi', 'ci', 'di', 'ei', 'fi', 'gi', 'hi', 'ii', 'ji', 'ki', 'li', 'mi', 'ni', 'oi', 'pi', 'qi', 'ri', 'si', 'ti', 'ui', 'vi', 'wi', 'xi', 'zi', 'j', 'aj', 'dj', 'jj', 'mj', 'oj', 'pj', 'tj', 'k', '2k', '6k', 'ak', 'bk', 'ck', 'dk', 'ek', 'fk', 'gk', 'hk', 'ik', 'kk', 'lk', 'nk', 'ok', 'rk', 'sk', 'uk', 'wk', 'l', 'al', 'cl', 'el', 'fl', 'il', 'll', 'ol', 'rl', 'sl', 'tl', 'ul', 'wl', 'xl', 'yl', 'm', 'am', 'bm', 'cm', 'dm', 'em', 'fm', 'gm', 'hm', 'im', 'km', 'lm', 'mm', 'om', 'pm', 'rm', 'sm', 'tm', 'um', 'ym', 'zm', 'n', 'an', 'cn', 'dn', 'en', 'gn', 'hn', 'in', 'kn', 'ln', 'mn', 'nn', 'on', 'pn', 'rn', 'un', 'wn', 'yn', 'án', 'én', 'ón', 'o', '0o', '2o', 'ao', 'bo', 'co', 'do', 'eo', 'fo', 'go', 'ho', 'io', 'jo', 'ko', 'lo', 'mo', 'no', 'oo', 'po', 'ro', 'so', 'to', 'uo', 'vo', 'wo', 'xo', 'yo', 'zo', 'ão', 'ío', 'ño', 'p', 'ap', 'dp', 'ep', 'gp', 'hp', 'ip', 'lp', 'mp', 'np', 'op', 'pp', 'qp', 'rp', 'sp', 'tp', 'up', 'vp', 'q', 'aq', 'gq', 'iq', 'r', 'ar', 'br', 'cr', 'dr', 'er', 'hr', 'ir', 'jr', 'lr', 'or', 'rr', 'sr', 'ur', 'yr', 'zr', 's', '0s', '1s', '2s', '3s', '4s', '5s', '6s', '7s', '8s', '9s', 'as', 'bs', 'cs', 'ds', 'es', 'fs', 'gs', 'hs', 'is', 'js', 'ks', 'ls', 'ms', 'ns', 'os', 'ps', 'qs', 'rs', 'ss', 'ts', 'us', 'vs', 'ws', 'ys', 'zs', 'és', 'ús', 't', 'at', 'bt', 'ct', 'dt', 'et', 'ft', 'gt', 'ht', 'it', 'jt', 'lt', 'mt', 'nt', 'ot', 'pt', 'rt', 'st', 'tt', 'ut', 'wt', 'xt', 'ét', 'ët', 'u', 'au', 'bu', 'cu', 'du', 'eu', 'fu', 'gu', 'hu', 'ju', 'ku', 'lu', 'mu', 'nu', 'ou', 'ru', 'su', 'tu', 'uu', 'vu', 'zu', 'v', 'av', 'bv', 'iv', 'jv', 'lv', 'mv', 'nv', 'ov', 'pv', 'rv', 'tv', 'uv', 'w', 'aw', 'ew', 'mw', 'ow', 'ww', 'x', '0x', '1x', '2x', '3x', '4x', '5x', '6x', '7x', '8x', 'ax', 'ex', 'fx', 'ix', 'kx', 'mx', 'nx', 'ox', 'rx', 'ux', 'xx', 'yx', 'gy', 'ty', 'oz', 'rz', 'tz', 'uz', 'wz', 'yz', 'zz', 'là', 'pá', 'yá', 'cé', 'hé', 'mé', 'né', 'ré', 'sé', 'rê', 'lí', 'ка', '楽部', '있다', '는데', '나봐', '모임', '𝘴𝘦', '𝘶𝘩', '𝘦𝘳', '𝘤𝘴', '𝘥𝘴']\n",
            "Epoch 1/2\n",
            "5401/5401 [==============================] - 64s 10ms/step - loss: 0.0955\n",
            "Epoch 2/2\n",
            "5401/5401 [==============================] - 55s 10ms/step - loss: 0.0907\n",
            "score: -50.849622036861284\n",
            "score: -57.54098040943037\n",
            "score: -51.00984055716362\n",
            "score: -57.40202788596044\n",
            "score: -51.055423494027956\n",
            "score: -57.28558785800825\n",
            "score: -51.0554799247254\n",
            "score: -57.25981536454215\n",
            "score: -51.07177114433303\n",
            "score: -57.248722860401536\n",
            "score: -51.09192586746006\n",
            "score: -57.26508197673757\n",
            "score: -51.10373368504964\n",
            "score: -57.27384520999189\n",
            "score: -51.10699101403986\n",
            "score: -57.27371343091761\n",
            "score: -51.10699101403986\n",
            "score: -57.27353378251826\n",
            "Nas will rock well; it ain't too many brain cells with my shawty\n",
            "I found 50 ki's in a world, we here talking to my clips is empty\n",
            "Battles and wars to the wall, Basquiat when I first heard the name eMeX\n",
            "Uh, all I do is splurge, might cop a seven-fifty\n",
            "And if you really are, ain't need me for this dynasty!\n",
            "Daz, don't be upset if I go to war so you property\n",
            "Fuck you to know that I got you for an afterparty\n",
            "You're lonely and you kinda look like River Phoenix\n",
            "I'll snap your trigger finger in the balla-nigga matrix\n",
            "Now grab them graham crackers and pass or that's that Kotex\n",
            "But back to your ass, then it would seem to be you? Yo no sé\n",
            "Thug style main, Thug style baby, Thug style y'know?\n",
            "Alright now, Li'l D, i'm gonna need a bus driver upper-cut\n",
            "Cause niggas used to need antifrizz, antifrizz\n",
            "Is every team's dream; Big L's a clever threat, a lyricist\n",
            "I wish I could really give a fuck, I just like a stylist\n",
            "Tell your boss a jerk, you’re gonna cuss a mouth full of the fittest\n",
            "Don't nut on this earth to infuse the birth when it come to harvest\n"
          ]
        }
      ],
      "source": [
        "# Main script:\n",
        "# 1. Define the network parameters:\n",
        "# - depth: depth of the network\n",
        "# - maxsyllables: maximum number of syllables for each line\n",
        "# - rap_length: number of lines in the lyrics created\n",
        "# - epochs: how many times the network is trained\n",
        "# 2. Call main(depth) function\n",
        "depth = 4\n",
        "maxsyllables = 16\n",
        "rap_length = 8\n",
        "epochs_to_train = 2\n",
        "\n",
        "main(depth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A7I9urFeizmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "draft project code3.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}